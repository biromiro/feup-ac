{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Load imports and data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import numpy as np \n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import seaborn as sns\n",
            "%matplotlib inline \n",
            "import missingno as msno\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "    # Do analysis in all data:\n",
            "    # (Safe because the rest of the notebook takes into account dates and whether the data is dev or comp, allowing it to keep the data separated)\n",
            "    # (It has been confirmed that this option produces the same results as running the other two options separately)\n",
            "DO_ANALYSIS = \"ALL-DATA\"\n",
            "\n",
            "    # Only do analysis on development data:\n",
            "    # (In order to reproduce data exploration from the report, run this script with only the development data)\n",
            "# DO_ANALYSIS = \"DEV-DATA\"\n",
            "\n",
            "    # Only run analysis on competition data:\n",
            "# DO_ANALYSIS = \"COMP-DATA\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "accounts = pd.read_csv('data/account.csv', sep=';')\n",
            "clients = pd.read_csv('data/client.csv', sep=';')\n",
            "disp = pd.read_csv('data/disp.csv', sep=';')\n",
            "districts = pd.read_csv('data/district.csv', sep=';')\n",
            "\n",
            "if DO_ANALYSIS == \"ALL-DATA\":\n",
            "    print(\"Running analysis on all data\")\n",
            "    cards = pd.read_csv('data/card.csv', sep=';')\n",
            "    loans = pd.read_csv('data/loan.csv', sep=';')\n",
            "    trans = pd.read_csv('data/trans.csv', sep=';')\n",
            "elif DO_ANALYSIS == \"DEV-DATA\":\n",
            "    print(\"Running analysis on development data\")\n",
            "    cards = pd.read_csv('data/card_dev.csv', sep=';')\n",
            "    loans = pd.read_csv('data/loan_dev.csv', sep=';')\n",
            "    trans = pd.read_csv('data/trans_dev.csv', sep=';')\n",
            "elif DO_ANALYSIS == \"COMP-DATA\":\n",
            "    print(\"Running analysis on competition data\")\n",
            "    cards = pd.read_csv('data/card_comp.csv', sep=';')\n",
            "    loans = pd.read_csv('data/loan_comp.csv', sep=';')\n",
            "    trans = pd.read_csv('data/trans_comp.csv', sep=';')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Data Understanding"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "loans"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def info(table, name):\n",
            "    print(\"==============\")\n",
            "    print(name)\n",
            "    print(\"--------------\")\n",
            "    print(table.info(verbose=True, max_cols=1000, memory_usage=False, show_counts=True))\n",
            "    print(\"--------------\")\n",
            "    print(\"Description of the table (table.describe()). For some columns, such as ids, these metrics are not useful and should be ignored.\")\n",
            "    print(table.describe())\n",
            "    print(\"--------------\")\n",
            "    for column in table.columns:\n",
            "        values = table[column].unique()\n",
            "        if len(values) < 10:\n",
            "            print(f\"\\tColumn {column} can have values {values}\")\n",
            "        if \"?\" in values:\n",
            "            print(f\"\\tColumn {column} has at least one value '?'\")\n",
            "    print(\"\\n\\n\")\n",
            "    \n",
            "info(accounts, \"accounts\")\n",
            "info(cards, \"cards\")\n",
            "info(clients, \"clients\")\n",
            "info(disp, \"disp\")\n",
            "info(districts, \"districts\")\n",
            "info(loans, \"loans\")\n",
            "info(trans, \"transactions\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "districts[districts['unemploymant rate \\'95 '] == '?']"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "districts[districts['no. of commited crimes \\'95 '] == '?']"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "- Null values: Only transactions_dev and district have null values\n",
            "    - transactions_dev: operation, k_symbol, bank, account\n",
            "    - district: unemploymant rate '95, no. of commited crimes '95\n",
            "\n",
            "- Dates: We should confirm that for a loan in a given date we only consider accounts/clients/transactions/etc from before that date, using the respective date fields"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Collected Data\n",
            "\n",
            "- account.csv - relation account (4500 objects) \n",
            "- client.csv - relation client (5369 objects)\n",
            "- disp.csv - relation disposition (5369 objects) \n",
            "- district.csv - relation demographic data (77 objects)\n",
            "- ~~relation permanent order (0/6471 objects)~~\n",
            "- trans_dev.csv - relation transaction (396685/1056320 objects)\n",
            "- card_dev.csv - relation credit card (177/892 objects)\n",
            "- loan_dev.csv - relation loan (328/682 objects)\n",
            "\n",
            "\n",
            "accounts : 4500 objects\n",
            " #  | Column    |   Non-Null Count | type \n",
            "--- | ------     |  -------------- | ----- \n",
            " 0 |  account_id  | 4500 non-null |  PRIMARY KEY \n",
            " 1  | district_id|  4500 non-null |  FOREIGN KEY \n",
            " 2  | frequency  |  4500 non-null |  enum('monthly issuance', 'issuance after transaction', 'weekly issuance')\n",
            " 3  | date       |  4500 non-null |  YYMMDD\n",
            "\n",
            "\n",
            "clients : 5369 objects\n",
            " #  | Column        |Non-Null Count|  type\n",
            "--- | ------        |--------------|  -----\n",
            " 0  | client_id     |5369 non-null |  PRIMARY KEY\n",
            " 1  | birth_number | 5369 non-null |  YYMMDD + 5000 if woman\n",
            " 2   |district_id |  5369 non-null |  FOREIGN KEY\n",
            "\n",
            "\n",
            "disp : 5369 objects\n",
            " #  | Column     | Non-Null Count | type \n",
            "--- | ------     | -------------- | ----- \n",
            " 0  | disp_id    | 5369 non-null  | PRIMARY KEY \n",
            " 1  | client_id  | 5369 non-null  | FOREIGN KEY \n",
            " 2  | account_id | 5369 non-null  | FOREIGN KEY \n",
            " 3  | type       | 5369 non-null  | enum('OWNER', 'DISPONENT')\n",
            "\n",
            "\n",
            "districts : 77 objects\n",
            " #  | Column                                            | Non-Null Count | type  \n",
            "--- | ------                                            | -------------- | -----  \n",
            " 0  | code                                              | 77 non-null    | PRIMARY KEY  \n",
            " 1  | name                                              | 77 non-null    | UNIQUE KEY \n",
            " 2  | region                                            | 77 non-null    | enum('Prague', 'central Bohemia', 'south Bohemia', 'west Bohemia', 'north Bohemia', 'east Bohemia', 'south Moravia', 'north Moravia')\n",
            " 3  | no. of inhabitants                                | 77 non-null    | int  \n",
            " 4  | no. of municipalities with inhabitants < 499      | 77 non-null    | int  \n",
            " 5  | no. of municipalities with inhabitants 500-1999   | 77 non-null    | int  \n",
            " 6  | no. of municipalities with inhabitants 2000-9999  | 77 non-null    | int  \n",
            " 7  | no. of municipalities with inhabitants >10000     | 77 non-null    | int  \n",
            " 8  | no. of cities                                     | 77 non-null    | int  \n",
            " 9  | ratio of urban inhabitants                       |  77 non-null    | float\n",
            " 10 | average salary                                  |   77 non-null    | int (currency unit)  \n",
            " 11 | unemploymant rate '95                          |    77 non-null    | float \n",
            " 12 | unemploymant rate '96                         |     77 non-null    | float\n",
            " 13 | no. of enterpreneurs per 1000 inhabitants    |      77 non-null    | int  \n",
            " 14 | no. of commited crimes '95                  |       77 non-null    | int \n",
            " 15 | no. of commited crimes '96                 |        77 non-null    | int  \n",
            "\n",
            "transactions : 396685/1056320 objects\n",
            " #  | Column    |  Non-Null Count |  type  \n",
            "--- | ------    |  -------------- |  -----  \n",
            " 0  | trans_id  |  396685 non-null|  PRIMARY KEY  \n",
            " 1  | account_id|  396685 non-null|  FOREIGN KEY  \n",
            " 2  | date      |  396685 non-null|  YYMMDD\n",
            " 3  | type      |  396685 non-null|  enum('credit', 'withdrawal', 'withdrawal in cash') \n",
            " 4  | operation |  325924 non-null|  enum('credit in cash', 'collection from another bank', 'withdrawal in cash', 'remittance to another bank', 'credit card withdrawal')\n",
            " 5  | amount    |  396685 non-null|  float64 (currency unit)\n",
            " 6  | balance   |  396685 non-null|  float64 (currency unit)\n",
            " 7  | k_symbol  |  211441 non-null|  enum('interest credited', ' ', 'household', 'payment for statement', 'insurrance payment', 'sanction interest if negative balance', 'old-age pension')\n",
            " 8  | bank      |  97242 non-null |  string (other bank ID)\n",
            " 9  | account   |  102229 non-null|  account (other bank's account ID)\n",
            "\n",
            "- type=\"withdrawal in cash\" is redundant with operation=\"withdrawal in cash\"\n",
            "\n",
            "cards : 177/892 objects\n",
            " #  | Column  | Non-Null Count | type \n",
            "--- | ------  | -------------- | ----- \n",
            " 0  | card_id | 177 non-null   | PRIMARY KEY \n",
            " 1  | disp_id | 177 non-null   | FOREIGN KEY \n",
            " 2  | type    | 177 non-null   | enum('classic', 'junior', 'gold')\n",
            " 3  | issued  | 177 non-null   | YYMMDD \n",
            "\n",
            "loans_dev : 328/682 objects\n",
            " #  | Column     | Non-Null Count | type\n",
            "--- | ------     | -------------- | -----\n",
            " 0  | loan_id    | 328 non-null   | PRIMARY KEY\n",
            " 1  | account_id | 328 non-null   | FOREIGN KEY\n",
            " 2  | date       | 328 non-null   | YYMMDD\n",
            " 3  | amount     | 328 non-null   | derived(duration*payments)\n",
            " 4  | duration   | 328 non-null   | int (number of months)\n",
            " 5  | payments   | 328 non-null   | int (currency unit/month)\n",
            " 6  | **status** |     328 non-null  |  TARGET (1 = paid, -1 = not paid)\n",
            "\n",
            "- binarize status (1 = not paid, 0 = paid)\n",
            "- encode duration by year (is by month at the moment, but always multiples of 12)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Check table association multiplicities"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Account -*----------1-> District\n",
            "\n",
            "# How many accounts has each district\n",
            "\n",
            "accounts_count_per_district_array = accounts.value_counts('district_id').sort_index().array\n",
            "accounts_count_per_district = { name: accounts_count_per_district_array[idx - 1] for idx, name in districts[['code ', 'name ']].values}\n",
            "\n",
            "\n",
            "accounts_count_per_region = {} \n",
            "for idx, region in districts[['code ', 'region']].values:\n",
            "    accounts_count_per_region[region] = accounts_count_per_region.get(region, 0) + accounts_count_per_district_array[idx - 1]\n",
            "\n",
            "def dict_barplot(dict):\n",
            "    \"\"\"From a dict {x:y} it plots a barplot\"\"\"\n",
            "    lenx = len(dict.keys())\n",
            "    plt.figure(figsize=(lenx/4, 4))\n",
            "    plt.bar(range(lenx), list(dict.values()), align='center')\n",
            "    plt.xticks(range(lenx), list(dict.keys()), rotation=90)\n",
            "    plt.show()\n",
            "\n",
            "dict_barplot(accounts_count_per_district)\n",
            "dict_barplot(accounts_count_per_region)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Client -*----------1-> District\n",
            "\n",
            "# How many clients has each district\n",
            "\n",
            "client_count_per_district_array = clients.value_counts('district_id').sort_index().array\n",
            "client_count_per_district = { name: client_count_per_district_array[idx - 1] for idx, name in districts[['code ', 'name ']].values}\n",
            "\n",
            "\n",
            "client_count_per_region = {} \n",
            "for idx, region in districts[['code ', 'region']].values:\n",
            "    client_count_per_region[region] = client_count_per_region.get(region, 0) + client_count_per_district_array[idx - 1]\n",
            "\n",
            "dict_barplot(client_count_per_district)\n",
            "dict_barplot(client_count_per_region)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Account <-1----------1..2- Disposition -1----------1-> Client\n",
            "\n",
            "\n",
            "clients_dict = {}\n",
            "for idx, client, account, type in disp[['disp_id', 'client_id', 'account_id', 'type']].values:\n",
            "    if client in clients_dict:\n",
            "        print(\"DUPLICATE CLIENT\", clients_dict[client])\n",
            "        # THERE ARE NO DUPLICATE CLIENTS: client_id is just as unique as disp_id\n",
            "        \n",
            "    clients_dict[client] = clients_dict.get(client, 0) + 1\n",
            "\n",
            "print(\"No clients missing from disposition:\", set(clients['client_id'].values) == set(disp['client_id'].values))\n",
            "print(\"No accounts missing from disposition:\", set(accounts['account_id'].values) == set(disp['account_id'].values))\n",
            "\n",
            "# EVERY ACCOUNT HAS 1 OWNER AND 0..1 DISPONENTS\n",
            "for account in set(accounts['account_id'].values):\n",
            "    disp_row = disp[disp['account_id'] == account]\n",
            "    types = disp_row['type'].value_counts()\n",
            "    if types.get('OWNER', 0) != 1:\n",
            "        print(\"Account\", account, \"has\", types.get('OWNER', 0), \"owners\")\n",
            "    if types.get('DISPONENT', 0) != 0 and types.get('DISPONENT', 0) != 1:\n",
            "        print(\"Account\", account, \"has\", types.get('DISPONENT', 0), \"disponents\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# acc_district != owner_district != disponent_district\n",
            "for account, acc_district in accounts[['account_id', 'district_id']].values:\n",
            "    disp_row = disp[disp['account_id'] == account]\n",
            "    owner_id = disp_row[disp_row['type'] == 'OWNER']['client_id'].values[0]\n",
            "    owner = clients[clients['client_id'] == owner_id]\n",
            "    owner_district = owner['district_id'].values[0]\n",
            "\n",
            "    disponent_id = disp_row[disp_row['type'] == 'DISPONENT']\n",
            "    if disponent_id.shape[0] == 1:\n",
            "        disponent_id = disponent_id['client_id'].values[0]\n",
            "        disponent = clients[clients['client_id'] == disponent_id]\n",
            "        disponent_district = disponent['district_id'].values[0]\n",
            "        print(acc_district, owner_district, disponent_district)\n",
            "    else:\n",
            "        print(acc_district, owner_district)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Card -0..1----------1-> Disponent\n",
            "disponents_dict = {}\n",
            "for idx, disponent in cards[['card_id', 'disp_id']].values:\n",
            "    if disponent in disponents_dict:\n",
            "        print(\"DUPLICATE DISPONENT\", disponents_dict[disponent])\n",
            "        # THERE ARE NO DUPLICATE DISPONENTS: disp_id is just as unique as card_id\n",
            "    disponents_dict[disponent] = disponents_dict.get(disponent, 0) + 1\n",
            "\n",
            "# There are disp without cards\n",
            "print(\"No disps missing from cards:\", set(disp['disp_id'].values) == set(cards['disp_id'].values))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Transaction -0..*----------1-> Account\n",
            "print(\"No accounts missing from transactions:\", set(accounts['account_id'].values) == set(trans['account_id'].values))\n",
            "\n",
            "accounts_dict = {account: 0 for account in accounts['account_id'].values}\n",
            "for idx, account in trans[['trans_id', 'account_id']].values:\n",
            "    accounts_dict[account] = accounts_dict.get(account, 0) + 1\n",
            "\n",
            "print(\"Accounts in dev have between\", min(accounts_dict.values()), \"and\", max(accounts_dict.values()), \"transactions\")\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Loan -0..1----------1-> Account\n",
            "accounts_dict = {}\n",
            "for idx, account in loans[['loan_id', 'account_id']].values:\n",
            "    if account in accounts_dict:\n",
            "        print(\"DUPLICATE ACCOUNT\", accounts_dict[account])\n",
            "        # THERE ARE NO DUPLICATE ACCOUNTS: account_id is just as unique as loan_id\n",
            "    accounts_dict[account] = accounts_dict.get(account, 0) + 1\n",
            "\n",
            "# There are accounts without loans\n",
            "print(\"No accounts missing from loans:\", set(accounts['account_id'].values) == set(loans['account_id'].values))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Plots and statistics"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "accounts['frequency'].hist()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "disp['type'].hist()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# x labels rotated 90º\n",
            "g = sns.histplot(districts, x='region')\n",
            "_ = g.set_xticklabels(g.get_xticklabels(), rotation=90)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Correlation of missing values (how much a value missing in one column is correlated with a value being missing in another column)\n",
            "msno.heatmap(trans)\n",
            "\n",
            "# Bank and account very correlated, as expected (both are missing at the same time)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "cards['issued'].hist()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sns.scatterplot(trans, x='amount', y='balance', hue='type')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Data Preparation\n",
            "\n",
            "Also includes the parts of data understanding and exploration which require some preparation."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### District"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Consider '?' as NaN and treat respetive columns as floats, so we can plot the correlation matrix\n",
            "districts.replace('?', np.nan, inplace=True)\n",
            "districts['no. of commited crimes \\'95 '] = districts['no. of commited crimes \\'95 '].astype(float)\n",
            "districts['unemploymant rate \\'95 '] = districts['unemploymant rate \\'95 '].astype(float)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def corr_plot(df, size=(13, 9), annot=True):\n",
            "    # Compute the correlation matrix\n",
            "    corr = df.corr()\n",
            "\n",
            "    # Generate a mask for the upper triangle\n",
            "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
            "\n",
            "    # Set up the matplotlib figure\n",
            "    f, ax = plt.subplots(figsize=size)\n",
            "\n",
            "    # Generate a custom diverging colormap\n",
            "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
            "\n",
            "    # Draw the heatmap with the mask and correct aspect ratio\n",
            "    sns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n",
            "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=annot, fmt=\".2f\")\n",
            "\n",
            "corr_plot(districts.drop(columns=['code ', 'region', 'name ']))\n",
            "\n",
            "# High correlation between number of inhabitants and number of commited crimes\n",
            "# Also between number of commited crimes in different years\n",
            "# Also between number of unemployment rate in different years\n",
            "# Also between average salary and commited crimes"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Correlation between number of commited crimes and number of inhabitants suggests that \n",
            "# crimes per capita would give more useful information\n",
            "districts['no. of commited crimes \\'95 '] = districts['no. of commited crimes \\'95 '] / districts['no. of inhabitants']\n",
            "districts['no. of commited crimes \\'96 '] = districts['no. of commited crimes \\'96 '] / districts['no. of inhabitants']"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sns.histplot(np.log(districts['no. of inhabitants']), kde=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Since we only have one row with missing values, it seams reasonable to complete the missing \n",
            "# values of unemployment rate and commited crimes with the mean values of the other rows\n",
            "districts['unemploymant rate \\'95 '].fillna(districts['unemploymant rate \\'95 '].mean(), inplace=True)\n",
            "districts['no. of commited crimes \\'95 '].fillna(districts['no. of commited crimes \\'95 '].mean(), inplace=True)\n",
            "\n",
            "# Note: the districts table is the same for dev and comp (only one value), so it is safe to do the mean, as there is \n",
            "# no extra comp data that was missing in the dev data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "districts.drop(['code ', 'region', 'name '], axis=1).describe()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "districts"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Merge tables"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Merge the tables based on the foreign keys, in order to have one row per loan with all relevant information for that loan\n",
            "\n",
            "# Merge loans and accounts and with the account district information\n",
            "df = pd.merge(loans, accounts, on='account_id', how='left', suffixes=('_loan', '_account'), validate='one_to_one')\n",
            "df = pd.merge(df, districts, left_on='district_id', right_on='code ', how='left', suffixes=(None, '_account_district'), validate='many_to_one')\n",
            "\n",
            "# Merge dispositions with clients and card information\n",
            "reduced_disp = pd.merge(disp, clients, on='client_id', how='left', suffixes=('_disp', '_client'), validate='one_to_one')\n",
            "reduced_disp = pd.merge(reduced_disp, cards, on='disp_id', how='left', suffixes=('_disp', '_card'), validate='one_to_one')\n",
            "# Missing cards replaced with \"no card\"\n",
            "reduced_disp['type_card'] = reduced_disp['type_card'].fillna('no card')\n",
            "# Merge that with the client district information\n",
            "reduced_disp = pd.merge(reduced_disp, districts, left_on='district_id', right_on='code ', how='left', suffixes=(None, '_client_district'), validate='many_to_one')\n",
            "\n",
            "# Filter by owners\n",
            "owners = reduced_disp[reduced_disp['type_disp'] == 'OWNER']\n",
            "owners.columns = owners.columns.map(lambda x: str(x) + '_owner' if x != 'account_id' else x)\n",
            "\n",
            "# Filter by the other disponent\n",
            "disponents = reduced_disp[reduced_disp['type_disp'] == 'DISPONENT']\n",
            "disponents.columns = disponents.columns.map(lambda x: str(x) + '_disponent' if x != 'account_id' else x)\n",
            "\n",
            "# Merge the owners and other disponents with the loans\n",
            "df = pd.merge(df, owners, on='account_id', how='left', suffixes=(None, '_something_wrong'), validate='one_to_one')\n",
            "df = pd.merge(df, disponents, on='account_id', how='left', suffixes=(None, '_something_wrong'), validate='one_to_one')"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Create new features based on transactions data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# This takes into account\n",
            "\n",
            "def filter_relevants(trans_dev, account_id, date):\n",
            "    # Take into account the date of the loan, so that future transactions are never considered\n",
            "    return trans_dev.loc[trans_dev['account_id'] == account_id].loc[trans_dev['date'] < date]\n",
            "\n",
            "rows_trans_dev = [filter_relevants(trans, row['account_id'], row['date_loan']) for _, row in df.iterrows()]\n",
            "\n",
            "def count_condition(df, condition):\n",
            "    return df.loc[condition].shape[0]\n",
            "\n",
            "def find_credit(subtrans):\n",
            "    return subtrans.loc[(subtrans['type'] == 'credit') | (subtrans['operation'] == 'credit in cash')]\n",
            "\n",
            "def find_withdrawal(subtrans):\n",
            "    # Takes into account the redudancy of the type \"withdrawal in cash\" which should be an operation, since the type would just be \"withdrawal\"\n",
            "    return subtrans.loc[(subtrans['type'] == 'withdrawal') | (subtrans['type'] == 'withdrawal in cash') | (subtrans['operation'] == 'withdrawal in cash') | (subtrans['operation'] == 'credit card withdrawal')]\n",
            "\n",
            "def signed_mean(subtrans):\n",
            "    return (\n",
            "        pd.concat([\n",
            "            find_credit(subtrans)['amount'],\n",
            "            -find_withdrawal(subtrans)['amount']\n",
            "        ])\n",
            "    ).mean()\n",
            "\n",
            "# Count categorical values\n",
            "df['count_trans_credits'] = [find_credit(subtrans).shape[0] for subtrans in rows_trans_dev]\n",
            "df['count_trans_withdrawals'] = [find_withdrawal(subtrans).shape[0] for subtrans in rows_trans_dev]\n",
            "df['count_trans_credit_cash'] = [count_condition(subtrans, (subtrans['operation'] == 'credit in cash')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_withdrawal_cash'] = [count_condition(subtrans, (subtrans['operation'] == 'withdrawal in cash') | (subtrans['type'] == 'withdrawal in cash')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_withdrawal_card'] = [count_condition(subtrans, (subtrans['operation'] == 'credit card withdrawal')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_collection_other_bank'] = [count_condition(subtrans, (subtrans['operation'] == 'collection from another bank')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_remittance_other_bank'] = [count_condition(subtrans, (subtrans['operation'] == 'remittance to another bank')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_ksymbol_interest_credited'] = [count_condition(subtrans, (subtrans['k_symbol'] == 'interest credited')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_ksymbol_household'] = [count_condition(subtrans, (subtrans['k_symbol'] == 'household')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_ksymbol_payment_for_statement'] = [count_condition(subtrans, (subtrans['k_symbol'] == 'payment for statement')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_ksymbol_insurance_payment'] = [count_condition(subtrans, (subtrans['k_symbol'] == 'insurance payment')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_ksymbol_sanction_interest_if_negative_balance'] = [count_condition(subtrans, (subtrans['k_symbol'] == 'sanction interest if negative balance')) for subtrans in rows_trans_dev]\n",
            "df['count_trans_ksymbol_oldage_pension'] = [count_condition(subtrans, (subtrans['k_symbol'] == 'old-age pension')) for subtrans in rows_trans_dev]\n",
            "\n",
            "# The balance of the account after the last transaction\n",
            "df['last_trans_balance'] = [subtrans.loc[subtrans['date'] == subtrans['date'].max()]['balance'].values[0] for subtrans in rows_trans_dev]\n",
            "\n",
            "# Means\n",
            "df['mean_trans_balance'] = [subtrans['balance'].mean() for subtrans in rows_trans_dev]\n",
            "df['mean_trans_amount_credit'] = [find_credit(subtrans)['amount'].mean() for subtrans in rows_trans_dev]\n",
            "df['mean_trans_amount_withdrawal'] = [find_withdrawal(subtrans)['amount'].mean() for subtrans in rows_trans_dev]\n",
            "# mean of |amount| (both credit and withdrawal count as positive values)\n",
            "df['mean_trans_amount_absolute'] = [subtrans['amount'].mean() for subtrans in rows_trans_dev]\n",
            "# signed mean of amount (credit is positive, withdrawal is negative)\n",
            "df['mean_trans_amount_signed'] = [signed_mean(subtrans) for subtrans in rows_trans_dev]\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "for column in ['last_trans_balance', 'mean_trans_balance', 'mean_trans_amount_credit', 'mean_trans_amount_withdrawal', 'mean_trans_amount_absolute', 'mean_trans_amount_signed']:\n",
            "    print(f\"Column {column} has NaNs:\", df.isna().any()[column])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Since there were no transactions, on average the amount withdrawn should be 0\n",
            "df['mean_trans_amount_withdrawal'].fillna(0, inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Drop ids\n",
            "df.drop(columns=['account_id', 'disp_id_owner', 'client_id_owner', 'type_disp_owner', 'card_id_owner', 'disp_id_disponent', 'client_id_disponent', 'type_disp_disponent', 'card_id_disponent'], inplace=True)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Extract birthdate and sex from birth_number"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df['owner_male'] = df['birth_number_owner'].apply(lambda x: 0 if int(str(x)[2:4]) > 12 else 1)\n",
            "df['owner_birthdate'] = df['birth_number_owner'].apply(lambda x: x-5000 if int(str(x)[2:4]) > 12 else x)\n",
            "df['disponent_male'] = df['birth_number_disponent'].apply(lambda x: (0 if int(str(x)[2:4]) > 12 else 1) if not pd.isna(x) else x)\n",
            "df['disponent_birthdate'] = df['birth_number_disponent'].apply(lambda x: (x-5000 if int(str(x)[2:4]) > 12 else x) if not pd.isna(x) else x)\n",
            "df.drop(columns=['amount', 'birth_number_owner', 'birth_number_disponent', 'code ', 'code _owner', 'code _disponent'], inplace=True)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Rename columns so that they are easier to use and more uniform"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.rename(columns={\n",
            "    'loan_id': 'Id', \n",
            "    'status': 'Predicted',\n",
            "    'date_loan': 'loan_date', \n",
            "    'duration': 'loan_duration', \n",
            "    'payments': 'loan_payments', \n",
            "    'district_id': 'account_district_code',\n",
            "    'name ': 'account_district_name', # removed below\n",
            "    'region': 'account_district_region',\n",
            "    'no. of inhabitants': 'account_district_no_inhabitants',\n",
            "    'no. of municipalities with inhabitants < 499 ': 'account_district_no_municipalities_0_499',\n",
            "    'no. of municipalities with inhabitants 500-1999': 'account_district_no_municipalities_500_1999',\n",
            "    'no. of municipalities with inhabitants 2000-9999 ': 'account_district_no_municipalities_2000_9999',\n",
            "    'no. of municipalities with inhabitants >10000 ': 'account_district_no_municipalities_10000_plus',\n",
            "    'no. of cities ': 'account_district_no_cities',\n",
            "    'ratio of urban inhabitants ': 'account_district_ratio_urban_inhabitants',\n",
            "    'average salary ': 'account_district_average_salary',\n",
            "    'unemploymant rate \\'95 ': 'account_district_unemployment_rate_95',\n",
            "    'unemploymant rate \\'96 ': 'account_district_unemployment_rate_96',\n",
            "    'no. of enterpreneurs per 1000 inhabitants ': 'account_district_no_enterpreneurs_per_1000_inhabitants',\n",
            "    'no. of commited crimes \\'95 ': 'account_district_no_crimes_95',\n",
            "    'no. of commited crimes \\'96 ': 'account_district_no_crimes_96',\n",
            "    'frequency': 'account_frequency', \n",
            "    'date_account': 'account_date', \n",
            "    'owner_male': 'owner_male',\n",
            "    'owner_birthdate': 'owner_birthdate',\n",
            "    'district_id_owner': 'owner_district_code',\n",
            "    'name _owner': 'owner_district_name', # removed below\n",
            "    'region_owner': 'owner_district_region',\n",
            "    'no. of inhabitants_owner': 'owner_district_no_inhabitants',\n",
            "    'no. of municipalities with inhabitants < 499 _owner': 'owner_district_no_municipalities_0_499', \n",
            "    'no. of municipalities with inhabitants 500-1999_owner': 'owner_district_no_municipalities_500_1999',\n",
            "    'no. of municipalities with inhabitants 2000-9999 _owner': 'owner_district_no_municipalities_2000_9999',\n",
            "    'no. of municipalities with inhabitants >10000 _owner': 'owner_district_no_municipalities_10000_plus',\n",
            "    'no. of cities _owner': 'owner_district_no_cities',\n",
            "    'ratio of urban inhabitants _owner': 'owner_district_ratio_urban_inhabitants',\n",
            "    'average salary _owner': 'owner_district_average_salary',\n",
            "    'unemploymant rate \\'95 _owner': 'owner_district_unemployment_rate_95',\n",
            "    'unemploymant rate \\'96 _owner': 'owner_district_unemployment_rate_96',\n",
            "    'no. of enterpreneurs per 1000 inhabitants _owner': 'owner_district_no_enterpreneurs_per_1000_inhabitants',\n",
            "    'no. of commited crimes \\'95 _owner': 'owner_district_no_crimes_95',\n",
            "    'no. of commited crimes \\'96 _owner': 'owner_district_no_crimes_96',\n",
            "    'type_card_owner': 'owner_card_type', \n",
            "    'issued_owner': 'owner_card_issued',\n",
            "    'disponent_male': 'disponent_male',\n",
            "    'disponent_birthdate': 'disponent_birthdate',\n",
            "    'district_id_disponent': 'disponent_district_code',\n",
            "    'name _disponent': 'disponent_district_name', # removed below\n",
            "    'region_disponent': 'disponent_district_region',\n",
            "    'no. of inhabitants_disponent': 'disponent_district_no_inhabitants',\n",
            "    'no. of municipalities with inhabitants < 499 _disponent': 'disponent_district_no_municipalities_0_499',\n",
            "    'no. of municipalities with inhabitants 500-1999_disponent': 'disponent_district_no_municipalities_500_1999',\n",
            "    'no. of municipalities with inhabitants 2000-9999 _disponent': 'disponent_district_no_municipalities_2000_9999',\n",
            "    'no. of municipalities with inhabitants >10000 _disponent': 'disponent_district_no_municipalities_10000_plus',\n",
            "    'no. of cities _disponent': 'disponent_district_no_cities',\n",
            "    'ratio of urban inhabitants _disponent': 'disponent_district_ratio_urban_inhabitants',\n",
            "    'average salary _disponent': 'disponent_district_average_salary',\n",
            "    'unemploymant rate \\'95 _disponent': 'disponent_district_unemployment_rate_95',\n",
            "    'unemploymant rate \\'96 _disponent': 'disponent_district_unemployment_rate_96',\n",
            "    'no. of enterpreneurs per 1000 inhabitants _disponent': 'disponent_district_no_enterpreneurs_per_1000_inhabitants',\n",
            "    'no. of commited crimes \\'95 _disponent': 'disponent_district_no_crimes_95',\n",
            "    'no. of commited crimes \\'96 _disponent': 'disponent_district_no_crimes_96',\n",
            "    'type_card_disponent': 'disponent_card_type', # removed below\n",
            "    'issued_disponent': 'disponent_card_issued',  # removed below\n",
            "    'count_trans_credits': 'count_trans_credits',\n",
            "    'count_trans_withdrawals': 'count_trans_withdrawals', \n",
            "    'count_trans_credit_cash': 'count_trans_credit_cash',\n",
            "    'count_trans_withdrawal_cash': 'count_trans_withdrawal_cash', \n",
            "    'count_trans_withdrawal_card': 'count_trans_withdrawal_card',\n",
            "    'count_trans_collection_other_bank': 'count_trans_collection_other_bank',\n",
            "    'count_trans_remittance_other_bank': 'count_trans_remittance_other_bank',\n",
            "    'count_trans_ksymbol_interest_credited': 'count_trans_ksymbol_interest_credited',\n",
            "    'count_trans_ksymbol_household': 'count_trans_ksymbol_household',\n",
            "    'count_trans_ksymbol_payment_for_statement': 'count_trans_ksymbol_payment_for_statement',\n",
            "    'count_trans_ksymbol_insurance_payment': 'count_trans_ksymbol_insurance_payment',\n",
            "    'count_trans_ksymbol_sanction_interest_if_negative_balance': 'count_trans_ksymbol_sanction_interest_if_negative_balance',\n",
            "    'count_trans_ksymbol_oldage_pension': 'count_trans_ksymbol_oldage_pension', \n",
            "    'last_trans_balance': 'last_trans_balance',\n",
            "    'mean_trans_balance': 'mean_trans_balance', \n",
            "    'mean_trans_amount_absolute': 'mean_trans_amount_absolute',\n",
            "    'mean_trans_amount_credit': 'mean_trans_amount_credit', \n",
            "    'mean_trans_amount_withdrawal': 'mean_trans_amount_withdrawal',\n",
            "    'mean_trans_amount_signed': 'mean_trans_amount_signed'\n",
            "}, inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Convert 1 to 0 (positive label) and -1 to 1 (negative label) in target column\n",
            "df['Predicted'] = df['Predicted'].apply(lambda x: 0 if x == 1 else (1 if x == -1 else np.nan))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Check that no column uses data from the future"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def check_after_sanity(df, col1, col2):\n",
            "    cond = (df[col1] > df[col2]) | (df[col1].isna()) | (df[col2].isna())\n",
            "    notcond = ~cond\n",
            "    print(f\"{col1} > {col2}: {cond.all()} ({notcond.sum()} rows)\")\n",
            "\n",
            "check_after_sanity(df, 'loan_date', 'account_date')\n",
            "check_after_sanity(df, 'loan_date', 'owner_card_issued')\n",
            "check_after_sanity(df, 'owner_card_issued', 'account_date')\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Create features based on dates"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "def parse_date_single(x):\n",
            "    if np.isnan(x):\n",
            "        return x\n",
            "    return '19' + str(x)[0:2] + '-' + str(x)[2:4] + '-' + str(x)[4:6]\n",
            "\n",
            "def parse_date(series):\n",
            "    return pd.to_datetime(series.apply(lambda x: parse_date_single(x)))\n",
            "\n",
            "def calculate_age(born, now):\n",
            "    born = parse_date(born)\n",
            "    now = parse_date(now)\n",
            "    born_md = born.apply(lambda x: (x.month, x.day))\n",
            "    now_md = now.apply(lambda x: (x.month, x.day))\n",
            "    return now.dt.year - born.dt.year - (now_md < born_md)\n",
            "\n",
            "def calculate_months(born, now):\n",
            "    born = parse_date(born)\n",
            "    now = parse_date(now)\n",
            "    return (now.dt.year - born.dt.year)*12 + (now.dt.month - born.dt.month) - (now.dt.day < born.dt.day)\n",
            "\n",
            "df['owner_age'] = calculate_age(df['owner_birthdate'], df['loan_date'])\n",
            "df['account_age_months'] = calculate_months(df['account_date'], df['loan_date'])\n",
            "df['disponent_age'] = calculate_age(df['disponent_birthdate'], df['loan_date'])\n",
            "\n",
            "df[df['owner_age'] < 17][['owner_age', 'disponent_age', 'Predicted']]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df[['owner_age', 'disponent_age', 'account_age_months']].describe()\n",
            "# There are minors in the dataset\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df[df['owner_age'] < 17][['owner_age', 'disponent_age', 'Predicted']]\n",
            "# Most minors don't have a disponent or have a disponent who is also a minor"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# These date columns are not needed anymore, as they were replaced by age columns\n",
            "df.drop(columns=['owner_birthdate', 'disponent_birthdate', 'account_date'], inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "corr_plot(df[['owner_male', 'owner_age', 'disponent_male', 'disponent_age',]], size=(3, 3))\n",
            "# Disponent male and owner male correlated negatively (shared accounts have a man and a woman)\n",
            "# Ages are correlated positively (account sharers have approximatedly the same age)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Missing data after processing"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Missing values after previous processing\n",
            "percent_missing = df.isnull().sum() * 100 / len(df)\n",
            "percent_missing.to_csv('output/percent_missing.csv')\n",
            "for row in percent_missing.iteritems():\n",
            "    print(f\"{row[0]}: {row[1]:.4}%\")\n",
            "\n",
            "# Missing values come from disponent information (since many accounts don't have another disponent)\n",
            "# and from the card issued date (since many clients don't have a card)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.drop(columns=['owner_card_issued'], inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "disp[disp['disp_id'].isin(cards['disp_id'])]['type'].value_counts()\n",
            "# All cards are from OWNERS - Remove disponent card information\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Names are strings (and are equivalent to codes) so they are only useful for human readability, not for the model\n",
            "df.drop(columns=['disponent_card_type', 'disponent_card_issued', 'account_district_name', 'owner_district_name', 'disponent_district_name'], inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# These work as primary keys, so they will not be able to help the model especially with the little training data we have\n",
            "df.drop(columns=['account_district_code', 'owner_district_code', 'disponent_district_code'], inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Replace disponent information by \"has_disponent\" feature\n",
            "\n",
            "df['has_disponent'] = df['disponent_male'].apply(lambda x: 0 if np.isnan(x) else 1)\n",
            "df.drop(columns=[\n",
            "    'disponent_district_region',\n",
            "    'disponent_district_no_inhabitants',\n",
            "    'disponent_district_no_municipalities_0_499',\n",
            "    'disponent_district_no_municipalities_500_1999',\n",
            "    'disponent_district_no_municipalities_2000_9999',\n",
            "    'disponent_district_no_municipalities_10000_plus',\n",
            "    'disponent_district_no_cities',\n",
            "    'disponent_district_ratio_urban_inhabitants',\n",
            "    'disponent_district_average_salary',\n",
            "    'disponent_district_unemployment_rate_95',\n",
            "    'disponent_district_unemployment_rate_96',\n",
            "    'disponent_district_no_enterpreneurs_per_1000_inhabitants',\n",
            "    'disponent_district_no_crimes_95',\n",
            "    'disponent_district_no_crimes_96',\n",
            "    'disponent_male',\n",
            "    'disponent_age',\n",
            "], inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Plots of processed data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sns.countplot(df, x='Predicted', palette='Set1')\n",
            "\n",
            "# Unbalanced data, sampling probably needed"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "corr_plot(df[[\n",
            "    'account_district_region',\n",
            "    'account_district_no_inhabitants',\n",
            "    'account_district_no_municipalities_0_499',\n",
            "    'account_district_no_municipalities_500_1999',\n",
            "    'account_district_no_municipalities_2000_9999',\n",
            "    'account_district_no_municipalities_10000_plus',\n",
            "    'account_district_no_cities',\n",
            "    'account_district_ratio_urban_inhabitants',\n",
            "    'account_district_average_salary',\n",
            "    'account_district_unemployment_rate_95',\n",
            "    'account_district_unemployment_rate_96',\n",
            "    'account_district_no_enterpreneurs_per_1000_inhabitants',\n",
            "    'account_district_no_crimes_95',\n",
            "    'account_district_no_crimes_96',\n",
            "    'owner_district_region',\n",
            "    'owner_district_no_inhabitants',\n",
            "    'owner_district_no_municipalities_0_499',\n",
            "    'owner_district_no_municipalities_500_1999',\n",
            "    'owner_district_no_municipalities_2000_9999',\n",
            "    'owner_district_no_municipalities_10000_plus',\n",
            "    'owner_district_no_cities',\n",
            "    'owner_district_ratio_urban_inhabitants',\n",
            "    'owner_district_average_salary',\n",
            "    'owner_district_unemployment_rate_95',\n",
            "    'owner_district_unemployment_rate_96',\n",
            "    'owner_district_no_enterpreneurs_per_1000_inhabitants',\n",
            "    'owner_district_no_crimes_95',\n",
            "    'owner_district_no_crimes_96',\n",
            "]], size=(16, 12))\n",
            "\n",
            "# Onwer and account district data are highly correlated, so we only need to use one of them\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sns.scatterplot(df, y='mean_trans_balance', x='last_trans_balance', hue='Predicted', palette='Set1')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sns.scatterplot(df, x='count_trans_credits', y='count_trans_withdrawals', hue='Predicted', palette='Set1')\n",
            "\n",
            "# credits and withdrawals are correlated"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "# 'Number of transactions of sanction interest because of negative balance'\n",
            "tempdf = df.rename(columns={'count_trans_ksymbol_sanction_interest_if_negative_balance': 'No. transactions sanction interest', 'owner_card_type': 'owner card type', 'Predicted': 'loan status'})\n",
            "tempdf.dropna(inplace=True)\n",
            "tempdf['loan status'] = tempdf['loan status'].apply(lambda x: \"Didn't pay loan\\n(Positive class)\" if x == 1 else \"Paid loan\\n(Negative class)\")\n",
            "\n",
            "plt.figure(figsize=(5, 2.75))\n",
            "plt.ylim(0, 320)\n",
            "\n",
            "sns.countplot(tempdf, x='No. transactions sanction interest', hue='loan status', palette='Set1', hue_order=[ \"Paid loan\\n(Negative class)\", \"Didn't pay loan\\n(Positive class)\",])\n",
            "\n",
            "\n",
            "# Most loaners with sanction interest for negative balance have not paid the loan\n",
            "# The only exception are the very few loaners with 6 of such transactions, which is an odd outlier"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Monthly loan payments as a function of balance after last transaction\n",
            "\n",
            "plt.figure(figsize=(7, 5))\n",
            "\n",
            "# plt.xlim(0, 9000)\n",
            "# plt.ylim(0, 500000)\n",
            "\n",
            "tempdf = df.rename(columns={'last_trans_balance': 'last transaction balance', 'loan_payments': 'loan payments', 'Predicted': 'loan status'})\n",
            "tempdf.dropna(inplace=True)\n",
            "tempdf['loan status'] = tempdf['loan status'].apply(lambda x: \"Didn't pay loan\\n(Positive class)\" if x == 1 else \"Paid loan\\n(Negative class)\")\n",
            "sns.scatterplot(tempdf, x='last transaction balance', y='loan payments', hue='loan status', palette='Set1', hue_order=[ \"Paid loan\\n(Negative class)\", \"Didn't pay loan\\n(Positive class)\",])\n",
            "\n",
            "# If the loan is big and the balance of the account after its last transaction is low, it’s likely the client will fail to pay the rest."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "sns.scatterplot(df, x='mean_trans_balance', y='loan_payments', hue='Predicted', palette='Set1')\n",
            "\n",
            "# The previous tendency is not as clear with the mean transaction balance"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Card types of owners of accounts who made a loan\n",
            "\n",
            "tempdf = df.rename(columns={'owner_card_type': 'owner card type', 'Predicted': 'loan status'})\n",
            "tempdf.dropna(inplace=True)\n",
            "tempdf['loan status'] = tempdf['loan status'].apply(lambda x: \"Didn't pay loan\\n(Positive class)\" if x == 1 else \"Paid loan\\n(Negative class)\")\n",
            "plt.figure(figsize=(4, 3.5))\n",
            "plt.ylim(0, 300)\n",
            "\n",
            "ax = sns.countplot(tempdf, x='owner card type', palette='Set1', order = tempdf['owner card type'].value_counts().index, hue=\"loan status\", hue_order=[ \"Paid loan\\n(Negative class)\", \"Didn't pay loan\\n(Positive class)\",])\n",
            "for p, label in zip(ax.patches, tempdf['owner card type'].value_counts() *100 / tempdf['owner card type'].count() + 0.011):\n",
            "    ax.annotate(f\"{label:.1f}%\", (p.get_x()+0.16, p.get_height()+ 5))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Imbalanced distribution of loan status\n",
            "tempdf = df.rename(columns={'Predicted': 'loan status'})\n",
            "tempdf['loan status'] = tempdf['loan status'].apply(lambda x: \"Didn't pay loan\\n(Positive class)\" if x == 1 else \"Paid loan\\n(Negative class)\")\n",
            "plt.figure(figsize=(3, 3.5))\n",
            "ax = sns.countplot(tempdf, x='loan status', palette='Set1', order = tempdf['loan status'].value_counts().index, hue_order=[\"Didn't pay loan\\n(Positive class)\", \"Paid loan\\n(Negative class)\"])\n",
            "for p, label in zip(ax.patches, tempdf['loan status'].value_counts() *100 / tempdf['loan status'].count() + 0.011):\n",
            "    ax.annotate(f\"{label:.1f}%\", (p.get_x()+0.25, p.get_height()+3))\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Loan amount is the product of loan payments and loan duration\n",
            "tempdf = loans.rename(columns={'payments': 'loan payments', 'duration': 'loan duration', 'amount': 'loan amount'})\n",
            "\n",
            "plt.figure(figsize=(5, 3))\n",
            "plt.xlim(0, 9000)\n",
            "plt.ylim(0, 500000)\n",
            "\n",
            "sns.scatterplot(tempdf, x='loan payments', y='loan amount', hue='loan duration', palette='Set1')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Programatically confirm the above\n",
            "(loans['amount'] == loans['duration']*loans['payments']).all()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Age of owners of accounts who made a loan\n",
            "tempdf = df.rename(columns={'owner_age': 'owner age'})\n",
            "plt.figure(figsize=(4, 3))\n",
            "plt.xlim(10, 65)\n",
            "\n",
            "ax = sns.histplot(tempdf, x='owner age', kde=True, bins=[10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65], palette='Set1',  kde_kws=dict(cut=3))\n",
            "\n",
            "ax.set_xticks([10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
            "ax.set_xticklabels([10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "tempdistricts = districts.rename({\n",
            "    'no. of inhabitants': 'no. inhabitants',\n",
            "    'no. of municipalities with inhabitants < 499 ': 'no. mcp < 499 inab.',\n",
            "    'no. of municipalities with inhabitants 500-1999': 'no. mcp 500-1999 inab.',\n",
            "    'no. of municipalities with inhabitants 2000-9999 ': 'no. mcp 2000-9999 inab.',\n",
            "    'no. of municipalities with inhabitants >10000 ': 'no. mcp >10000 inab.',\n",
            "    'no. of cities ': 'no. cities',\n",
            "    'ratio of urban inhabitants ': 'ratio urban inhabitants',\n",
            "    'average salary ': 'average salary',\n",
            "    'unemploymant rate \\'95 ': 'unemployment rate \\'95',\n",
            "    'unemploymant rate \\'96 ': 'unemployment rate \\'96',\n",
            "    'no. of enterpreneurs per 1000 inhabitants ': 'no. enterpreneurs',\n",
            "    'no. of commited crimes \\'95 ': 'no. crimes \\'95',\n",
            "    'no. of commited crimes \\'96 ': 'no. crimes \\'96',\n",
            "}, axis=1)\n",
            "\n",
            "corr_plot(tempdistricts.drop(columns=['code ', 'name ', 'region' ], axis=1))\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### Encode categorical features"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# encode string to int\n",
            "DISTRICT_REGION_ENCODING = {\n",
            "    'south Moravia': 0,\n",
            "    'north Moravia': 1,\n",
            "    'central Bohemia': 2,\n",
            "    'east Bohemia': 3,\n",
            "    'Prague': 4,\n",
            "    'north Bohemia': 5,\n",
            "    'south Bohemia': 6,\n",
            "    'west Bohemia': 7\n",
            "}\n",
            "\n",
            "CARD_TYPE_ENCODING = {'no card': 0, 'junior': 1, 'classic': 2, 'gold': 3}\n",
            "\n",
            "ACCOUNT_FREQUENCY_ENCODING = {'issuance after transaction': 0, 'weekly issuance': 1, 'monthly issuance': 2}\n",
            "\n",
            "df['account_frequency'].replace(ACCOUNT_FREQUENCY_ENCODING, inplace=True)\n",
            "df['account_district_region'].replace(DISTRICT_REGION_ENCODING, inplace=True)\n",
            "df['owner_district_region'].replace(DISTRICT_REGION_ENCODING, inplace=True)\n",
            "df['owner_card_type'].replace(CARD_TYPE_ENCODING, inplace=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Print all column names\n",
            "for i in df.columns: \n",
            "    print(f\"'{i}',\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "pd.set_option('display.max_columns', None)\n",
            "pd.set_option('display.max_rows', 20)\n",
            "df.head()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df.describe()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "corr_plot(df.drop(columns=['Predicted', 'Id', 'loan_duration']), annot=False)\n",
            "# Disponent male and owner male correlated negatively (man and woman)"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Save data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df = df.sort_values(by='loan_date')\n",
            "competition = df[df['Predicted'].isna()]\n",
            "data = df[~df['Predicted'].isna()]\n",
            "\n",
            "if DO_ANALYSIS == \"ALL-DATA\":\n",
            "    df.to_csv('output/loan.csv', index=False)\n",
            "\n",
            "if DO_ANALYSIS == \"ALL-DATA\" or DO_ANALYSIS == \"DEV-DATA\":\n",
            "    data.to_csv('output/loan_dev.csv', index=False)\n",
            "\n",
            "if DO_ANALYSIS == \"ALL-DATA\" or DO_ANALYSIS == \"COMP-DATA\":\n",
            "    competition.to_csv('output/loan_comp.csv', index=False)\n"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3.10.7 64-bit",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.7"
      },
      "orig_nbformat": 4,
      "vscode": {
         "interpreter": {
            "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
